{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f94c7eb-d84e-4792-bf8c-db49e4b1b991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce9c6047-f477-476a-a04a-98adfb577203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4 - Building Dynamic Workloads with Advanced Tasks\n",
    "\n",
    "In this demo, we will show how to build dynamic Lakeflow jobs using conditional logic (`if-else`) and iterative tasks (`for each` loop).\n",
    "\n",
    "This demo will cover:\n",
    "- Defining dependencies between tasks\n",
    "- Adding a conditional `if-else` task\n",
    "- Adding an iterative `for each` task\n",
    "\n",
    "### Learning Objective\n",
    "Create and visualize a dynamic Lakeflow job with multiple tasks and dependencies.\n",
    "\n",
    "![Lesson04_final_job](./Includes/images/Lesson04_final_job.png)\n",
    "\n",
    "After completing this demo, your job will look like above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "773cbebc-c9f0-4869-819f-65e1a60f0b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE (The cluster named 'labuser')\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "\n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "251bb18e-6c68-4576-b203-ddf7271aacad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this course. It will also set your default catalog to **dbacademy** and the schema to your specific schema name shown below using the `USE` statements.\n",
    "<br></br>\n",
    "\n",
    "\n",
    "```\n",
    "USE CATALOG dbacademy;\n",
    "USE SCHEMA dbacademy.<your unique schema name>;\n",
    "```\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course.\n",
    "\n",
    "**NOTE:** If you use Serverless V1 a warning will be returned. You can ignore the warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "127c3ab3-ebf4-4532-b451-ce7281c4c413",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac87b580-5fd0-4650-969b-0ba46ea016d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Explore Your Schema\n",
    "Complete the following to explore your **dbacademy.labuser** schema:\n",
    "\n",
    "1. In the left navigation bar, select the catalog icon:  ![Catalog Icon](./Includes/images/catalog_icon.png)\n",
    "\n",
    "2. Locate the catalog called **dbacademy** and expand the catalog.\n",
    "\n",
    "3. Expand your **labuser** schema. \n",
    "\n",
    "4. Notice that within your schema you will find two tables named as **sales_bronze**, **customers_bronze** and **orders_bronze**.\n",
    "\n",
    "**Note:** If you have completed the 2L Exercise, you may find additional tables under your schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c89118d-8cf4-41ce-967c-af1f44122c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## C. View Your Notebook\n",
    "\n",
    "Follow these steps to view the notebook files used in this job. All files are located in the **Task Files** folder within the directory for the corresponding lesson number.\n",
    "\n",
    "1. Navigate to (or click the link for) the notebook: [Task Files/Lesson 4 Files/4.1 - Joining Customers and Sales Table]($./Task Files/Lesson 4 Files/4.1 - Joining Customers and Sales Table)\n",
    "   - Review the notebook. It creates a new table by joining the **customers_bronze** and **sales_bronze** tables. Pay attention to the code that sets the task value for the key **has_duplicates**.\n",
    "\n",
    "2. Navigate to (or click the link for) the notebook: [Task Files/Lesson 4 Files/4.2 - Joining Customers and Orders Table]($./Task Files/Lesson 4 Files/4.2 - Joining Customers and Orders Table)\n",
    "   - Review the notebook. It creates a new table by joining the **customers_bronze** and **orders_bronze** tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9266aa01-5d47-484b-a8d6-af99c7890e74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## D. Adding Task in Job\n",
    "Complete the steps below to add new task into your Retail Job\n",
    "\n",
    "###D1. Creating the Starter Job\n",
    "1. Next, we will add the notebooks listed below as tasks to our job using the Databricks SDK. This approach avoids manually adding notebook tasks, as we've already done it in previous demonstrations and labs:\n",
    "\n",
    "\n",
    "   - **4.1 - Joining Customers and Sales Table**  \n",
    "\n",
    "   - **4.2 - Joining Customers and Orders Table**  \n",
    "\n",
    "   Run the cell below to build the starter job that we have been continually building in this course. These commands will set up your job with all work completed so far and add the required tasks for this demonstration.\n",
    "\n",
    "![Lesson04_starter_job](./Includes/images/Lesson04_starter_job.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8b96d07-3f2e-4ec7-a642-fca83527d31f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "job_tasks = [\n",
    "        {\n",
    "            'task_name': 'ingesting_orders',\n",
    "            'file_path': '/Task Files/Lesson 1 Files/1.1 - Creating orders table',\n",
    "            'depends_on': None\n",
    "        },\n",
    "        {\n",
    "            'task_name': 'ingesting_sales',\n",
    "            'file_path': '/Task Files/Lesson 1 Files/1.2 - Creating sales table',\n",
    "            'depends_on': None\n",
    "        },\n",
    "        {\n",
    "            'task_name': 'ingesting_customers',\n",
    "            'file_path': '/Task Files/Lesson 3 Files/3.1 - Creating customers table',\n",
    "            'depends_on': None\n",
    "        }\n",
    "        ,{\n",
    "            'task_name': 'customers_sales_summary',\n",
    "            'file_path': '/Task Files/Lesson 4 Files/4.1 - Joining Customers and Sales Table',\n",
    "            'depends_on': [\n",
    "                        {'task_key':'ingesting_customers'},\n",
    "                        {'task_key': 'ingesting_sales'}\n",
    "                        ]\n",
    "        }\n",
    "        ,{\n",
    "            'task_name' : 'customers_orders_report',\n",
    "            'file_path': '/Task Files/Lesson 4 Files/4.2 - Joining Customers and Orders Table',\n",
    "            'depends_on': None\n",
    "        }\n",
    "    ]\n",
    "\n",
    "myjob = DAJobConfig(job_name=f\"Demo_04_Retail_Job_{DA.schema_name}\",\n",
    "                    job_tasks=job_tasks,\n",
    "                    job_parameters=[\n",
    "                        {'name':'catalog', 'default':'dbacademy'},\n",
    "                        {'name':'schema', 'default':f'{DA.schema_name}'}\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f0f40c0-1064-472a-b7e1-49d269863f59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### D2. Set Dependencies on the Tasks\n",
    "\n",
    "In this step, we will modify the existing job to define task dependencies. Specifically, we'll configure the main task to run only after all preceding tasks have completed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5cdfe80-9bf7-4738-ab02-7dc1ad7db90c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Complete the following to review the job and set the following dependencies to the **customers_orders_report** task:\n",
    "   - **ingesting_orders**\n",
    "   - **ingesting_customers**\n",
    "\n",
    "1. Navigate to **Jobs and Pipelines** and open it in a new tab.\n",
    "\n",
    "2. Select your new job that starts with **Demo_04_Retail_Job_labuser**.\n",
    "\n",
    "3. Click on **Tasks** in the top navigation bar.\n",
    "\n",
    "4. Review your job. You should see five tasks: \n",
    "   - **customers_orders_report**.\n",
    "   - **ingesting_customers**, \n",
    "   - **ingesting_orders**, \n",
    "   - **ingesting_sales**, \n",
    "   - **customers_sales_summary**,\n",
    "\n",
    "5. Select the **customers_sales_summary** task. \n",
    "   - Notice that it depends on two tasks: **ingesting_customers** and **ingesting_sales**, with the dependency set to **All Succeeded**.\n",
    "\n",
    "6. Next, select the **customers_orders_report** task and set the following task options: \n",
    "\n",
    "   - In the **Depends on**, add **ingesting_orders** and **ingesting_customers**\n",
    "\n",
    "   - In **Run if dependencies**, set the dependency to **All Succeeded**.\n",
    "\n",
    "   - Select **Save task**.\n",
    "\n",
    "7. Click on **Run_now** to run the job.\n",
    "\n",
    "<br></br>\n",
    "#### Final Dependencies\n",
    "![Lesson04_dependencies](./Includes/images/Lesson04_dependencies.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ac788b0-1c3d-46bb-9684-91c2d0cc5bf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## E. Add an If/Else Conditional Task\n",
    "\n",
    "In this section, you will add a conditional task to your job that checks for duplicate records in the **customers_sales_silver** table (Task **customers_sales_summary**). \n",
    "\n",
    "Based on the result, the workflow will branch to handle duplicates appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b859e5e-84d4-4476-b3ce-6c0ae64e5a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### E1. Checking for Duplication Logic\n",
    "\n",
    "1. Recall the logic used to detect duplicates in the **customers_sales_silver** table. (The **customers_sales_summary** task creates the **customers_sales_silver** table.)\n",
    "\n",
    "2. In that notebook, we check whether the **customers_sales_silver** table contains any duplicate records. If duplicates are found, the result of this check (a boolean value) is stored as `has_duplicates` in the task output.\n",
    "\n",
    "**Code Reference:**\n",
    "\n",
    "        df = spark.sql(\"\"\"\n",
    "            SELECT * FROM customers_sales_silver\n",
    "        \"\"\")\n",
    "\n",
    "        duplicate_exists = df.count() > df.dropDuplicates().count()\n",
    "\n",
    "        dbutils.jobs.taskValues.set(key=\"has_duplicates\", value=duplicate_exists)\n",
    "\n",
    "**Notebook for Reference:**  \n",
    "[Task Files/Lesson 4 Files/4.1 - Joining Customers and Sales Table]($./Task Files/Lesson 4 Files/4.1 - Joining Customers and Sales Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cd29761-ca5d-404d-945a-7a2b55c3e2e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### E2. Create an If/Else Conditional Task\n",
    "\n",
    "Create an **If/else conditional** task to determine what to execute based on whether duplicate records are found.\n",
    "\n",
    "1. In your **Demo_04_Retail_Job_labuser** job, select **Add task**.\n",
    "\n",
    "2. In the dialog box, scroll down to the **Advanced** section and select the task type **If/else condition**.\n",
    "\n",
    "3. Name the new task **checking_for_duplicates**.\n",
    "\n",
    "4. Set the **Depend on**  value to the **customers_sales_summary** task.\n",
    "\n",
    "5. For the **Condition** field, use the parameter value created in the `customers_sales_summary` task:\n",
    "\n",
    "   **Dynamic Value References:**\n",
    "   This syntax leverages dynamic value references to access output variables from earlier tasks in your job. When a task runs (like `customers_sales_summary`), its results—including variables registered or output by the task (such as `has_duplicates`)—become available for downstream tasks.\n",
    "\n",
    "   **By referencing** `tasks.customers_sales_summary.values.has_duplicates`, you dynamically pass the value (whether duplicates exist) to the If/Else condition. This enables conditional branching based on run-time data rather than static configuration, making your workflow adaptable and responsive to actual results.\n",
    "\n",
    "    **Adding Condition Field:** \n",
    "     - To manually add the parameter value, select the `{}` in the **Condition** field. \n",
    "     - Find and click on `tasks.customers_sales_summary.values`, it will automatically add a suffix of `my_value` to it.\n",
    "     - Replace `my_value` with the task parameter created in the notebook: `has_duplicates`.\n",
    "\n",
    "6. Then set the condition to check if this value  `== true`\n",
    "\n",
    "7. Select **Save task** to create the conditional task.\n",
    "\n",
    "\n",
    "<br></br>\n",
    "##### IF/ELSE CONDITION TASK\n",
    "\n",
    "![Lesson04_conditional_task.png](./Includes/images/Lesson04_conditional_task.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ab53559-7275-4838-b3f5-5917f7604b73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### E3. Set the True Condition (Duplicates Exists) Task\n",
    "\n",
    "Complete the following steps to add a task that runs **only if duplicates are found** (`tasks.customers_sales_summary.values.has_duplicates == true`).\n",
    "\n",
    "1. Select the **checking_for_duplicates** task.\n",
    "\n",
    "2. Click **Add task**, and choose **Notebook**.\n",
    "\n",
    "3. Name the new task **dropping_duplicate_records**.\n",
    "\n",
    "4. Use the notebook [4.3 - If Condition: Dropping Duplicates]($./Task Files/Lesson 4 Files/4.3 - If Condition: Dropping Duplicates) as the task source.  \n",
    "   - This notebook includes logic to remove duplicate records from the **customers_sales_silver** table.\n",
    "\n",
    "5. In the **Depends on** field, set this task to depend on the **True** branch of the **checking_for_duplicates** task (`checking_for_duplicates (true)`).\n",
    "\n",
    "6. Click on **Create Task** \n",
    "<br></br>\n",
    "##### TRUE DEPENDENCY TASK\n",
    "\n",
    "![Lesson04_if_task](./Includes/images/Lesson04_if_task.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb9d7652-c789-4d22-ae81-01a7260e97ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### E4. Set the False Condition (No Duplicates) Task\n",
    "\n",
    "Complete the following steps to add a task that runs only if duplicates are not found (`tasks.customers_sales_summary.values.has_duplicates == false`).\n",
    "\n",
    "This setup ensures your job automatically handles duplicates if they exist, or proceeds to data transformation if no duplicates are found.\n",
    "\n",
    "1. Select the **checking_for_duplicates** task.\n",
    "\n",
    "2. Click **Add task**, and choose **Notebook**.\n",
    "\n",
    "3. Name the new task **transforming_customers_sales_table**.\n",
    "\n",
    "4. Use the notebook [Task Files/Lesson 4 Files/4.4 - Else Condition: Cleaning and Transforming Customers Sales Table]($./Task Files/Lesson 4 Files/4.4 - Else Condition: Cleaning and Transforming Customers Sales Table) as the task source.  \n",
    "   - This notebook includes logic to clean and transform the **customers_sales_silver** table.\n",
    "\n",
    "5. In the **Depends on** field, set this task to depend on the following:\n",
    "   - The **False** branch of the **checking_for_duplicates** task (`checking_for_duplicates (false)`).\n",
    "   - The **dropping_duplicate_records** task.\n",
    "\n",
    "6. In the **Run if dependencies** field, select **None Failed**.  \n",
    "   - This ensures:\n",
    "     - If there are no duplicates, the transformation runs immediately.\n",
    "     - If duplicates exist, the job runs the task **dropping_duplicate_records**, then proceeds with the transformation task **transforming_customers_sales_table**.\n",
    "\n",
    "7. Click on **Create Task**.\n",
    "\n",
    "8. Click on **Run now** button to run the job\n",
    "\n",
    "\n",
    "<br></br>\n",
    "##### FALSE DEPENDENCY TASK\n",
    "\n",
    "![Lesson04_false_task.png](./Includes/images/Lesson04_false_task.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56ecd2c8-07e7-492a-a539-27a1c0f9f46d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### E5. Job Confirmation  \n",
    "Confirm your job looks like the following after adding the **If/else condition** and associated tasks:\n",
    "\n",
    "\n",
    "![Lesson04_IfElse](./Includes/images/Lesson04_IfElse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51de6495-e1ed-4832-9c40-785bc57d28e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## F. Add a For Each Loop Task\n",
    "\n",
    "In this section, you will add a downstream task to **customers_orders_report** that uses a **For Each** loop. This loop allows the job to execute the same task multiple times, once for each item in a specified list or collection. Execution may happen sequentially or concurrently, depending on job configuration. \n",
    "\n",
    "In our case, from the customers_orders_silver table, we want to generate orders reports specifically for the states of **California, New York, and Virginia**. We will create three different tables to store state-specific data. We will use the same code script and dynamically pass the state name with the help of the **For Each** task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6bf7e19-8fb1-4f13-966c-2f0c63818077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### F1. Explore the Notebooks\n",
    "\n",
    "1. Review the notebook [Task Files/Lesson 4 Files/4.2 - Joining Customers and Orders Table]($./Task Files/Lesson 4 Files/4.2 - Joining Customers and Orders Table), which creates the **customers_orders_silver** table.\n",
    "\n",
    "2. The [Task Files/Lesson 4 Files/4.5 - For Each: Customer orders State]($./Task Files/Lesson 4 Files/4.5 - For Each: Customer orders State) notebook will be executed in a loop for each state mentioned above. This script dynamically takes the state value and runs it for each state, creating a state-specific table with customers_order_silver data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8198ab53-9ce6-40a3-8820-a1c4e1c4a9fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### F2. Creating a For Each Iterator Task (Part 1 of 2)\n",
    "\n",
    "The \"For Each\" task involves two steps: first, define the iterator, and then specify the script to be iterated. Now, complete the following to add a **For Each** iterator task to loop over a series of **state** values.\n",
    "\n",
    "1. In the same job, select the **customers_orders_report** task.\n",
    "\n",
    "2. Select **Add task** and select the task type **For each**.\n",
    "\n",
    "3. Name the task **customers_orders_state_wise_report_iterator**. \n",
    "\n",
    "4. Set the iterator **Inputs** field to `[\"CA\", \"NY\", \"VA\"]`.  \n",
    "  — These are the states with the highest number of customers.\n",
    "\n",
    "5. Leave the **Concurrency** setting blank (recommended for single-node runs to avoid slowing down the process).\n",
    "\n",
    "6. Set the **Depends on** field for this task to **customers_orders_report**.\n",
    "\n",
    "7. Ensure the **Run if dependencies** is set to **All succeeded**.\n",
    "\n",
    "8. Click on **Add a task to loop over**.\n",
    "\n",
    "#### For Each Iterator\n",
    "\n",
    "![Lesson04_For_Each_Task_Iterator.png](./Includes/images/Lesson04_For_Each_Task_Iterator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "795ceff0-c1a8-4d8f-aec6-5ee1d454c1f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### F3. Add a Task to Loop Over (Part 2 of 2)\n",
    "\n",
    "Now that the **For Each** task iterator is set, we need to specify a task to loop over. Complete the following to add the task to loop over.\n",
    "\n",
    "1. Now that the iterator is set. Select **Add a task to loop over**. \n",
    "\n",
    "2. Name the task to iterate over **customers_orders_state_wise_report**.\n",
    "\n",
    "3. Confirm the task **Type** is **Notebook** and the **Source** is **Workspace**.\n",
    "\n",
    "4. Set the notebook path to [Task Files/Lesson 4/4.5 - For Each: Customer orders State]($./Task Files/Lesson 4 Files/4.5 - For Each: Customer orders State), which is under the **Task Files** folder.\n",
    "\n",
    "5. Set **Compute** to **serverless**.\n",
    "\n",
    "6. Add a key-value parameter:\n",
    "   - For key, add **state**. \n",
    "   - For the value, click on the **{}** symbol and select **input**.  \n",
    "   - This will automatically pass each state code from the iterator loop to the notebook.\n",
    "\n",
    "7. Click **Create task**.\n",
    "\n",
    "<br></br>\n",
    "#### Iterator Task\n",
    "![Lesson04_iterator_task.pngg](./Includes/images/Lesson04_iterator_task.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fd2cc01-98d8-453d-b469-96bec548311e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## G. Run the Entire Job\n",
    "\n",
    "To execute your job:\n",
    "\n",
    "1. Click on **Run Now** to start the job.\n",
    "\n",
    "2. Go to the **Runs** tab to monitor the progress and view the results of each task.\n",
    "\n",
    "This will run all tasks in your job according to the dependencies and logic you have set up.\n",
    "\n",
    "**NOTE:** This job will take about 5 minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d9ee13f-1f65-4195-b2c3-76cb60cf102b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## H. Conclusion and Results\n",
    "\n",
    "When your job run is successful, Click on catalog icon, go to your schema under dbacademy catalog. Look out for new tables **customers_sales_gold** , **customers_orders_ca_silver**, **customers_orders_ny_silver** and **customers_orders_va_silver**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed7eeaec-3bfb-488c-92f5-75377004b27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The `customers_sales_gold` table does not require any transformation. It is our gold-tier table containing sales metrics such as **units_purchased, avg_price_per_unit, total_price**, customer details like **customer_id, customer_name, loyalty_segment**, and supporting order details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7d25277-a5b8-41b7-a98b-d9d82fa0df99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM customers_sales_gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39ed0a68-c863-43e2-b159-05fd86f1c4b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The tables **customers_orders_ca_silver**, **customers_orders_ny_silver**, and **customers_orders_va_silver** are state-specific and contain relevant data for each state. These tables will be further transformed to add business columns, which we will do in a future demo to create gold-tier tables. Now, query them to see the type of data they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "038964b0-159b-42a7-a65c-e288598187c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM customers_orders_ca_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33a54ac4-7d4c-4563-bd9f-d16203e2db71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM customers_orders_ny_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5768fad9-11f3-467b-a35d-e06e4ea5fcfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM customers_orders_va_silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40db8007-7d9f-40ca-b3ca-95510e82cb8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "4 Demo - Building Dynamic Workloads with Advanced Tasks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
